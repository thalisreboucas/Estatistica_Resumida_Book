[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estatisca Resumida",
    "section": "",
    "text": "Bem vindos\nEstatística Resumida BOOK é um livro que oferece uma introdução completa e acessível aos princípios e métodos da estatística, focando especialmente na sua aplicação prática. Este livro é destinado a estudantes, profissionais e entusiastas que desejam compreender e aplicar conceitos estatísticos de forma eficiente em diversas áreas.\nA obra inicia com uma explicação dos fundamentos da estatística, apresentando os principais conceitos, como população, amostra, variável, medidas de tendência central e de dispersão. Em seguida, aborda os diferentes tipos de estudos estatísticos e suas respectivas metodologias, incluindo estudos observacionais e experimentais.\nUma parte significativa do livro é dedicada à coleta, organização e análise de dados. Os leitores aprenderão técnicas para selecionar amostras representativas, conduzir pesquisas e experimentos, além de explorar e visualizar os dados utilizando gráficos e tabelas. A importância da interpretação correta dos resultados estatísticos é enfatizada ao longo de todo o texto.\nA obra também explora os principais métodos estatísticos, como inferência estatística, teste de hipóteses, regressão e correlação. Cada método é explicado de forma clara e ilustrado com exemplos do mundo real, permitindo aos leitores compreender como aplicar essas técnicas em situações reais.\nAlém disso, o livro aborda tópicos avançados, como análise multivariada, séries temporais e análise de sobrevivência, ampliando ainda mais o conhecimento estatístico dos leitores."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Análise Descritiva",
    "section": "",
    "text": "Em um conjuto de dados temos um número \\(n\\) de valores e a soma total desse conjuto de dados e a sua divisão pelo o valor de \\(n\\) nos dá a média, porém a média é influênciada por valores que fogem do padrão da amostra sendo o valor grande demais ou muito pequeno ,lembrando que a média pode ou não representar \\(50\\%\\) dos dados.\nSeja \\({\\displaystyle n}\\) o número total de valores e \\({\\displaystyle x_{i}}\\) cada valor, em que \\({\\displaystyle i=1,\\dots ,n}\\). Média aritmética é a soma dos valores \\({\\displaystyle x_{i}}\\) dividido pelo número total de valores \\({\\displaystyle n}\\):\n**Formula :**\n$$ \\bar{x} = \\dfrac{x_1 + \\ldots +x_n}{n} = \\frac{1}{n}\\sum_{i-1}^{n}x_i\n$$$$\n\n\n\nO termo “mediana” refere-se a “meio”. Dado um conjunto de informações numéricas, o valor central corresponde à mediana desse conjunto. Dessa forma, é importante que esses valores sejam colocados em ordem, seja crescente ou decrescente. Se houver uma quantidade ímpar de valores numéricos, a mediana será o valor central do conjunto numérico. Se a quantidade de valores for um número par, devemos fazer uma média aritmética dos dois números centrais, e esse resultado será o valor da mediana.\n\n\n\nA moda é a realização mais frequente em um conjunto de valores. O fenômeno acontece quando, em um banco de dados, há a repetição das informações encontradas em uma mesma variável.\nUma empresa de Tecnologia da Informação tem 20 funcionários contratados. A maioria deles (15) tem idade entre 20 e 25 anos. O restante (5) está na faixa de 30 e 40 anos. A maior recorrência de idade, no entanto, é de funcionários com 23 anos. São 5 no total — definindo a medida de posição ora apresentada.\nA moda pode ser definida em bimodal (quando ocorre a repetição de dois valores) ou multimodal (mais de dois valores repetidos). O caso dos cinco funcionários com 23 anos identificamos como multimodal.\n\n\n\nTemos que os Quartis são valores de divisão na qual divide os conjuntado de dados em 4 partes, na qual temos:\n1. Primeiro Quartil divide em \\(25\\%\\) em uma amostra ordena os valores inferiores.\n2. Segundo Quartil ou Mediana divide em \\(50\\%\\) em uma amostra ordena os valores inferiores.\n3. Terceiro Quartil divide em \\(75\\%\\) em uma amostra ordena os valores superiores.\nSão utilizados para entender como se comporta os dados em cada quartil correspondente até aquele ponto.\n**Intervalo interquartil(IIQ)** avalia a dispersão de dados somente depois de ordená-los em ordem crescente. O intervalo interquartil é calculado com base no cálculo de quartis, sendo o primeiro quartil (inferior), o quartil intermediário (mediana), o terceiro quartil (superior), que estão ligados ao conceito de quantil. A diferença entre o quartil superior e o quartil inferior determina o intervalo interquartil\n\n\n\n\n\n\n\n\n\nA variância é determinada pela média dos quadrados das diferenças entre cada uma das observações e a média aritmética da amostra. O cálculo é feito com base na seguinte fórmula:\n- Variancia Amostral\n- Variância Populacional\n$$$$\\sigma ^{2}={\\frac {1}{N}}\\sum _{{i=1}}^{N}\\left(x_{i}-\\mu \\right)^{2},$$$$\nSendo,\n- \\(\\sigma^2\\) : variância\n- \\(x_i\\): valor observado\n- \\(bar(x)\\) : média aritmética da amostra\n- n: número de dados observados\n\n\n\n$$$$\\sigma(S) = \\sqrt{Variância}$$$$\n\n\n\n$$$$cv = \\dfrac{\\sigma}{\\bar(x)}\n$$$$\n\n\n\n\nAs tabelas de contingência são usadas para registrar observações independentes de duas ou mais variáveis aleatórias, normalmente qualitativas.\nSuponha que tenhamos duas variáveis de uma população, A e B, e queremos relacioná-la com outras duas variáveis C e D . Retirando-se uma amostra aleatória dessa população, uma tabela de contingência conteria as frequências em cada classe, a tabela seria da seguinte forma:\n| | Variáveis |\n|-----------|-------------------------------|----|\n| Variáveis | C | D |\n| A | 5 | 3 |\n| B | 3 | 49 |\n| Total | 8 | 52 |\nEm posse da tabela de contingência podemos então realizar testes para saber se há ou não independência entre variáveis.\n\n\nO teste de McNemar é utilizado em tabelas de contingência, essencialmente em tabelas $(2\\times2)$, com dados pareados para comparar frequências marginais, que em ’outras palavras significa que o teste compara se houve mudança nas proporções no objeto de estudo antes e depois de uma intervenção.\nAs hipóteses do teste são:\n$$\n\\left\\{ \\begin{array}{l}\nH_0: \\text{As variáveis linha e coluna possuem as mesmas proporções},\\\\\nH_1: \\text{As variáveis linha e coluna possuem proporções diferentes}. \\\\\n\\end{array} \\right.\n$$$$\nA estatística do teste, \\(Q\\), é dada por:\n$$$$ Q=\\cfrac{(a-d)^2}{(a+d)}$$$$\nem que \\(Q \\sim \\chi^2(1)\\), lê-se \\(Q\\) segue uma distribuição qui-quadrado com 1 grau de liberdade.\n\n\n\n\nA tabela de classes é usada quando temos dados brutos provenientes de uma variável contínua, e então nós as agrupamos para a construção de uma tabela, em intervalos que também são conhecidos por classes.\nSuponhamos que desejamos construir K classes. O valor mínimo da nossa amostra(mín) e o máximo(máx). A partir dessas informações, calculamos a amplitude total(AT):\n$$$$ \\text{AT = máx – mín.}\n$$\n$$\nComo o número de classes (k) é dada por:\n\\(k = 1+3,3\\log(n)\\)\nA amplitude de cada classe (h) é dada por:\n$$ h = \\frac{AT}{k}$$$$"
  },
  {
    "objectID": "intro.html#medidas-de-posição",
    "href": "intro.html#medidas-de-posição",
    "title": "Análise Descritiva",
    "section": "Medidas de Posição",
    "text": "Medidas de Posição\n\nMédia\nEm um conjuto de dados temos um número \\(n\\) de valores e a soma total desse conjuto de dados e a sua divisão pelo o valor de \\(n\\) nos dá a média, porém a média é influênciada por valores que fogem do padrão da amostra sendo o valor grande demais ou muito pequeno ,lembrando que a média pode ou não representar \\(50\\%\\) dos dados.\nSeja \\({\\displaystyle n}\\) o número total de valores e \\({\\displaystyle x_{i}}\\) cada valor, em que \\({\\displaystyle i=1,\\dots ,n}\\) . Média aritmética é a soma dos valores \\({\\displaystyle x_{i}}\\) dividido pelo número total de valores \\({\\displaystyle n}\\) :\nFormula :\n\\[\\bar{x} = \\dfrac{x_1 + \\ldots +x_n}{n} = \\frac{1}{n}\\sum_{i-1}^{n}x_i\\]\n\n\nMediana\nO termo “mediana” refere-se a “meio”. Dado um conjunto de informações numéricas, o valor central corresponde à mediana desse conjunto. Dessa forma, é importante que esses valores sejam colocados em ordem, seja crescente ou decrescente. Se houver uma quantidade ímpar de valores numéricos, a mediana será o valor central do conjunto numérico. Se a quantidade de valores for um número par, devemos fazer uma média aritmética dos dois números centrais, e esse resultado será o valor da mediana.\n\n\nModa\nA moda é a realização mais frequente em um conjunto de valores. O fenômeno acontece quando, em um banco de dados, há a repetição das informações encontradas em uma mesma variável.\nUma empresa de Tecnologia da Informação tem 20 funcionários contratados. A maioria deles (15) tem idade entre 20 e 25 anos. O restante (5) está na faixa de 30 e 40 anos. A maior recorrência de idade, no entanto, é de funcionários com 23 anos. São 5 no total — definindo a medida de posição ora apresentada.\nA moda pode ser definida em bimodal (quando ocorre a repetição de dois valores) ou multimodal (mais de dois valores repetidos). O caso dos cinco funcionários com 23 anos identificamos como multimodal.\n\n\nQuartil\nTemos que os Quartis são valores de divisão na qual divide os conjuntado de dados em 4 partes, na qual temos:\n\nPrimeiro Quartil divide em \\(25\\%\\) em uma amostra ordena os valores inferiores.\nSegundo Quartil ou Mediana divide em \\(50\\%\\) em uma amostra ordena os valores inferiores.\nTerceiro Quartil divide em \\(75\\%\\) em uma amostra ordena os valores superiores.\n\nSão utilizados para entender como se comporta os dados em cada quartil correspondente até aquele ponto.\nIntervalo interquartil(IIQ) avalia a dispersão de dados somente depois de ordená-los em ordem crescente. O intervalo interquartil é calculado com base no cálculo de quartis, sendo o primeiro quartil (inferior), o quartil intermediário (mediana), o terceiro quartil (superior), que estão ligados ao conceito de quantil. A diferença entre o quartil superior e o quartil inferior determina o intervalo interquartil"
  },
  {
    "objectID": "intro.html#medidas-de-dispersão",
    "href": "intro.html#medidas-de-dispersão",
    "title": "Análise Descritiva",
    "section": "Medidas de Dispersão",
    "text": "Medidas de Dispersão\n\nAmplitude\n\n\nVariância\nA variância é determinada pela média dos quadrados das diferenças entre cada uma das observações e a média aritmética da amostra. O cálculo é feito com base na seguinte fórmula:\n- Variancia Amostral\n\\[\\sigma^{2}={\\frac{1}{n-1}}\\sum _{{i=1}}^{n}\\left(x_{i}-\\mu \\right)^{2}\\]\n- Variância Populacional\n\\[\\sigma^{2}={\\frac{1}{N}}\\sum _{{i=1}}^{N}\\left(x_{i}-\\mu \\right)^{2}\\]\nSendo,\n- \\(\\sigma^2\\) : variância\n- \\(x_i\\) : valor observado\n- \\(bar(x)\\) : média aritmética da amostra\n- \\(n\\): número de dados observados\n\n\nDesvio Padrão\n\\[\n\\\\sigma(S) = \\\\sqrt{Variância}\n\\]\n\n\nCoeficiente de Variação\n\\[cv = \\dfrac{\\sigma}{\\bar(x)}\\]"
  },
  {
    "objectID": "intro.html#tabela-de-contingência",
    "href": "intro.html#tabela-de-contingência",
    "title": "Análise Descritiva",
    "section": "Tabela de contingência",
    "text": "Tabela de contingência\nAs tabelas de contingência são usadas para registrar observações independentes de duas ou mais variáveis aleatórias, normalmente qualitativas.\nSuponha que tenhamos duas variáveis de uma população, A e B, e queremos relacioná-la com outras duas variáveis C e D . Retirando-se uma amostra aleatória dessa população, uma tabela de contingência conteria as frequências em cada classe, a tabela seria da seguinte forma:\n\nTabela de contingência\n\n\nVariáveis\nC\nD\n\n\n\n\nA\n5\n3\n\n\nB\n3\n49\n\n\nTotal\n8\n52\n\n\n\nEm posse da tabela de contingência podemos então realizar testes para saber se há ou não independência entre variáveis.\n\nTeste de McNemar\nO teste de McNemar é utilizado em tabelas de contingência, essencialmente em tabelas \\((2\\times2)\\) , com dados pareados para comparar frequências marginais, que em ’outras palavras significa que o teste compara se houve mudança nas proporções no objeto de estudo antes e depois de uma intervenção.\nAs hipóteses do teste são:\n\\[\\left\\{ \\begin{array}{l}H_0: \\text{As variáveis linha e coluna possuem as mesmas proporções},\\\\H_1: \\text{As variáveis linha e coluna possuem proporções diferentes}.\\end{array} \\right.\\]\nA estatística do teste, \\(Q\\) , é dada por:\n\\[Q=\\dfrac{(a-d)^2}{(a+d)}\\]\nem que \\(Q \\sim \\chi^2(1)\\) , lê-se \\(Q\\) segue uma distribuição qui-quadrado com 1 grau de liberdade."
  },
  {
    "objectID": "intro.html#tabela-de-classes",
    "href": "intro.html#tabela-de-classes",
    "title": "Análise Descritiva",
    "section": "Tabela de classes",
    "text": "Tabela de classes\nA tabela de classes é usada quando temos dados brutos provenientes de uma variável contínua, e então nós as agrupamos para a construção de uma tabela, em intervalos que também são conhecidos por classes.\nSuponhamos que desejamos construir \\(K\\) classes. O valor mínimo da nossa amostra(mín) e o máximo(máx). A partir dessas informações, calculamos a amplitude total(AT):\n\\(\\text{AT = máx - mín.}\\)\nComo o número de classes (k) é dada por:\n\\(k = 1+3,3\\log(n)\\)\nA amplitude de cada classe (h) é dada por:\n\\(h=\\frac{AT}{k}\\)"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "References"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Summary",
    "section": "",
    "text": "Summary\nIn summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "09-graficos.html#barras",
    "href": "09-graficos.html#barras",
    "title": "6  Gráficos",
    "section": "6.1 Barras",
    "text": "6.1 Barras\nEste é um gráfico que utiliza barras retangulares e o seu comprimento representa os dados proporcionalmente a escala do eixo que estão os dados. Estas Barras podem estar na vertical ou na Horizontal.Além disso, é um gráfico muito utilizado para representar valores discretos.Neles conseguimos compreender a quantidade de cada item pelo tamanho da barra retangular.\n\nHistograma é um gráfico de barras que demonstra a distribuição de dados e frequências. A base de cada uma de suas barras representa uma classe e a altura a frequência em que a classe ocorre."
  },
  {
    "objectID": "09-graficos.html#circular-pizza",
    "href": "09-graficos.html#circular-pizza",
    "title": "6  Gráficos",
    "section": "6.2 Circular (Pizza)",
    "text": "6.2 Circular (Pizza)\nEste é um gráfico que cada fatia representa uma categoria de dados que compõe o todo. Juntas, as fatias representam 100%. O tamanho de cada fatia é relativo à sua porção do todo. Se há muitas categorias de dados apresentadas, a leitura do gráfico de pizza pode ficar bem prejudicada. O intuito do gráfico de pizza é que todas as informações fiquem claras à primeira vista.\nUm gráfico de rosca é um tipo de gráfico de pizza, mas em vez de apresentar os dados em um formato de círculo sólido, apresenta as informações em um formato de rosca. Eles têm basicamente a mesma função e podem ser usados alternadamente, de acordo do aspecto visual que você estiver buscando."
  },
  {
    "objectID": "09-graficos.html#boxplot",
    "href": "09-graficos.html#boxplot",
    "title": "6  Gráficos",
    "section": "6.3 Boxplot",
    "text": "6.3 Boxplot\nEste é um gráfico que utiliza um diagrama de caixa é uma ferramenta gráfica que permite visualizar a distribuição e valores discrepantes (outliers) dos dados.Além disso, o boxplot também é uma disposição gráfica comparativa.As medidas de estatísticas descritivas como o mínimo, máximo, primeiro quartil, segundo quartil ou mediana e o terceiro quartil formam o boxplot.\n\n6.3.1 Boxplot + Violino\nO “violino” são as curvas no entorno do gráfico boxplot, e representa a função densidade de probabilidade estimada via kernel (basicamente, as curvas mais largas representam maior densidade de pontos, ou seja, existe uma maior frequência de pontos). Esse tipo de representação pode ser útil para alguns conjuntos de dados, pois pelo fato do boxplot resumir os dados em 5 medidas descritivas, pode haver perda de informação. Já o “violino” resume os dados em uma função densidade, caracterizando melhor o conjunto de dados."
  },
  {
    "objectID": "09-graficos.html#linhas",
    "href": "09-graficos.html#linhas",
    "title": "6  Gráficos",
    "section": "6.4 Linhas",
    "text": "6.4 Linhas\nEste é um gráfico de linhas continuas para a visualização de dados em linhas do tempo, serve para ver a tendencia e a sazonalidade do que esta ocorrendo com os dados,geralmente o eixo Y são onde fica os dias,meses ou anos e o eixo X é onde fica uma escala discreta ou continua em relação ao tipo de dado."
  },
  {
    "objectID": "10-referencia.html",
    "href": "10-referencia.html",
    "title": "7  Referências",
    "section": "",
    "text": "Agresti, A. (2002). Categorical data analysis. Second edition. New York: Wiley. Pages 91–101\nAgresti, A. (2007). An Introduction to Categorical Data Analysis, 2nd ed. New York: John Wiley & Sons. Page 38\nAgresti, A. (2007). An Introduction to Categorical Data Analysis, 2nd ed. New York: John Wiley & Sons. Page 29\nBonferroni, C. E., Teoria statistica delle classi e calcolo delle probabilità, Pubblicazioni del R Istituto Superiore di Scienze Economiche e Commerciali di Firenze 193\nBussab,W. O.; Morettin, P. A.Estatística Básica - 7 Edição, Atual Editora, 1987.\nR Core Team (2020). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.\nLance, C.E., & Vandenberg, R.J. (Eds.). (2014). More Statistical and Methodological Myths and Urban Legends: Doctrine, Verity and Fable in Organizational and Social Sciences (1st ed.). Routledge. https://doi.org/10.4324/9780203775851\nAssociação entre variáveis.Disponível em: http://sweet.ua.pt/andreia.hall/TEA/Capcorrel.pdf. Acesso:10 de janeiro 2018.\nBussab,W. O.; Morettin, P. A.Estatística Básica - 7 Edição, Atual Editora, 1987.\nBolfarine, H.;Sandoval, M. C. Introdução à Inferência Estatística} - 2 Edição, Editora SBM, 2010.\nTeste de hipótese. Disponível em:http://www.ufscar.br/jcfogo/Estat_2/arquivos/Teste_Hipotese.pdf. Acesso:12 de janeiro 2018.\nViali,L.Apostila Testes Hipóteses Não Paramétricos.Porto Alegre, 2008.\nHANIFAN, Lyda J. The rural school community center. The Annals of the American Academy of Political and Social Science, v. 67, n. 1, p. 130-138, 1916.\nJOHNSON, R A. WICHERN, D. W. Applied Multivariate Statistical Analysis. Vol 5. No. 8. Upper Saddle River, NJ: Prentice hall, 2002.\nDE PÁDUA BRAGA, Antônio; DE LEON FERREIRA, André Carlos Ponce; LUDERMIR, Teresa Bernarda. Redes neurais artificiais: teoria e aplicações. Rio de Janeiro, Brazil:: LTC Editora, 2007.\nHAYKIN, Simon. Redes neurais: princípios e prática. Bookman Editora, 2007..\nMORETTIN, Pedro Alberto; BUSSAB, WILTON OLIVEIRA. Estatística básica. Editora Saraiva, 2017.\nPAULA, Gilberto Alvarenga. Modelos de regressão: com apoio computacional. São Paulo: IME-USP, 2004.\nScikit-Learn, Multilayer Perceptron. Disponível em:https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html."
  },
  {
    "objectID": "02-descritiva.html#medidas-de-posição",
    "href": "02-descritiva.html#medidas-de-posição",
    "title": "Análise Descritiva",
    "section": "Medidas de Posição",
    "text": "Medidas de Posição\nMedidas de posição são estatísticas usadas para descrever a posição relativa de um valor em um conjunto de dados. Elas ajudam a entender onde um valor específico se encaixa em relação aos outros valores no conjunto.\n\nMédia\nEm um conjuto de dados temos um número \\(n\\) de valores e a soma total desse conjuto de dados e a sua divisão pelo o valor de \\(n\\) nos dá a média, porém a média é influênciada por valores que fogem do padrão da amostra sendo o valor grande demais ou muito pequeno ,lembrando que a média pode ou não representar \\(50\\%\\) dos dados.\nSeja \\({\\displaystyle n}\\) o número total de valores e \\({\\displaystyle x_{i}}\\) cada valor, em que \\({\\displaystyle i=1,\\dots ,n}\\). Média aritmética é a soma dos valores \\({\\displaystyle x_{i}}\\) dividido pelo número total de valores \\({\\displaystyle n}\\):\nFormula : \\(\\bar{x} = \\dfrac{x_1 + \\ldots +x_n}{n} = \\frac{1}{n}\\sum_{i-1}^{n}x_i\\)\n\n\nMediana\nO termo “mediana” refere-se a “meio”. Dado um conjunto de informações numéricas, o valor central corresponde à mediana desse conjunto. Dessa forma, é importante que esses valores sejam colocados em ordem, seja crescente ou decrescente. Se houver uma quantidade ímpar de valores numéricos, a mediana será o valor central do conjunto numérico. Se a quantidade de valores for um número par, devemos fazer uma média aritmética dos dois números centrais, e esse resultado será o valor da mediana.\n\n\nModa\nA moda é a realização mais frequente em um conjunto de valores. O fenômeno acontece quando, em um banco de dados, há a repetição das informações encontradas em uma mesma variável.\nUma empresa de Tecnologia da Informação tem 20 funcionários contratados. A maioria deles (15) tem idade entre 20 e 25 anos. O restante (5) está na faixa de 30 e 40 anos. A maior recorrência de idade, no entanto, é de funcionários com 23 anos. São 5 no total — definindo a medida de posição ora apresentada.\nA moda pode ser definida em bimodal (quando ocorre a repetição de dois valores) ou multimodal (mais de dois valores repetidos). O caso dos cinco funcionários com 23 anos identificamos como multimodal.\n\n\nQuartil\nTemos que os Quartis são valores de divisão na qual divide os conjuntado de dados em 4 partes, na qual temos:\n\nPrimeiro Quartil divide em \\(25\\%\\) em uma amostra ordena os valores inferiores.\nSegundo Quartil ou Mediana divide em \\(50\\%\\) em uma amostra ordena os valores inferiores.\nTerceiro Quartil divide em \\(75\\%\\) em uma amostra ordena os valores superiores.\n\nSão utilizados para entender como se comporta os dados em cada quartil correspondente até aquele ponto.\nIntervalo interquartil(IIQ) avalia a dispersão de dados somente depois de ordená-los em ordem crescente. O intervalo interquartil é calculado com base no cálculo de quartis, sendo o primeiro quartil (inferior), o quartil intermediário (mediana), o terceiro quartil (superior), que estão ligados ao conceito de quantil. A diferença entre o quartil superior e o quartil inferior determina o intervalo interquartil"
  },
  {
    "objectID": "02-descritiva.html#medidas-de-dispersão",
    "href": "02-descritiva.html#medidas-de-dispersão",
    "title": "Análise Descritiva",
    "section": "Medidas de Dispersão",
    "text": "Medidas de Dispersão\n\nAmplitude\n\n\nVariância\nA variância é determinada pela média dos quadrados das diferenças entre cada uma das observações e a média aritmética da amostra. O cálculo é feito com base na seguinte fórmula:\n\nVariancia Amostral\nVariância Populacional\n\n\\(\\sigma^{2}=\\frac{1}{N}\\sum_{i=1}^{N}\\left(x\\_{i}-\\mu \\right)^{2}\\),\nSendo,\n\n\\(\\sigma^2\\) : variância\n\\(x_i\\): valor observado\n\\(bar(x)\\) : média aritmética da amostra\nn: número de dados observados\n\n\n\nDesvio Padrão\n\\(\\sigma(S) = \\sqrt{Variância}\\)\n\n\nCoeficiente de Variação\n\\(cv = \\dfrac{\\sigma}{\\bar(x)}\\)"
  },
  {
    "objectID": "02-descritiva.html#tabela-de-contingência",
    "href": "02-descritiva.html#tabela-de-contingência",
    "title": "Análise Descritiva",
    "section": "Tabela de contingência",
    "text": "Tabela de contingência\nAs tabelas de contingência são usadas para registrar observações independentes de duas ou mais variáveis aleatórias, normalmente qualitativas.\nSuponha que tenhamos duas variáveis de uma população, A e B, e queremos relacioná-la com outras duas variáveis C e D . Retirando-se uma amostra aleatória dessa população, uma tabela de contingência conteria as frequências em cada classe, a tabela seria da seguinte forma:\n\n\n\n\nVariáveis\n\n\n\n\n\nVariáveis\nC\nD\n\n\nA\n5\n3\n\n\nB\n3\n49\n\n\nTotal\n8\n52\n\n\n\nEm posse da tabela de contingência podemos então realizar testes para saber se há ou não independência entre variáveis.\n\nTeste de McNemar\nO teste de McNemar é utilizado em tabelas de contingência, essencialmente em tabelas \\((2\\times2)\\), com dados pareados para comparar frequências marginais, que em ’outras palavras significa que o teste compara se houve mudança nas proporções no objeto de estudo antes e depois de uma intervenção.\nAs hipóteses do teste são:\n\\(\\begin{cases} H_0: \\text{As variáveis linha e coluna possuem as mesmas proporções},\\\\ H_1: \\text{As variáveis linha e coluna possuem proporções diferentes}. \\end{cases}\\)\nA estatística do teste, \\(Q\\), é dada por: \\[ Q=\\cfrac{(a-d)^2}{(a+d)} \\] em que \\(Q \\sim \\chi^2(1)\\), lê-se \\(Q\\) segue uma distribuição qui-quadrado com 1 grau de liberdade."
  },
  {
    "objectID": "02-descritiva.html#tabela-de-classes",
    "href": "02-descritiva.html#tabela-de-classes",
    "title": "Análise Descritiva",
    "section": "Tabela de classes",
    "text": "Tabela de classes\nA tabela de classes é usada quando temos dados brutos provenientes de uma variável contínua, e então nós as agrupamos para a construção de uma tabela, em intervalos que também são conhecidos por classes.\nSuponhamos que desejamos construir K classes. O valor mínimo da nossa amostra(mín) e o máximo(máx). A partir dessas informações, calculamos a amplitude total(AT):\n\\(\\text{AT = máx – mín.}\\) Como o número de classes (k) é dada por: \\(k = 1+3,3 \\log(n)\\).\nA amplitude de cada classe (h) é dada por:\n\\(h = \\frac{AT}{k}.\\)"
  },
  {
    "objectID": "03-correlacao.html#coeficiente-de-cramér",
    "href": "03-correlacao.html#coeficiente-de-cramér",
    "title": "Análise de Correlação",
    "section": "Coeficiente de Cramér",
    "text": "Coeficiente de Cramér\nO coeficiente de Cramér é uma medida entre duas variáveis medidas numa escala categórica. Portanto pode ser aplicado em situações onde a informação se encontra distribuída por categorias nominais não ordenáveis.\nEste coeficiente obtém-se diretamente a partir da estatística \\(\\chi_v^2\\) através da expressão\n\\[\nC = \\sqrt{\\dfrac{\\chi_v^2}{n(l-1)}}\n\\]\nonde n representa o número total de observações e l representa o mínimo entre o número de linhas e colunas na tabela de contingência.\nA partir do valor do coeficiente de Cramér é possível efetuar um teste às hipóteses\n\\(\\begin{cases} H_0:\\text{  As variáveis são independentes;} \\\\ H_1:\\text{  As variáveis não são independentes.} \\end{cases}\\)"
  },
  {
    "objectID": "03-correlacao.html#coeficiente-de-correlação-ponto-biserial",
    "href": "03-correlacao.html#coeficiente-de-correlação-ponto-biserial",
    "title": "Análise de Correlação",
    "section": "Coeficiente de Correlação Ponto Biserial",
    "text": "Coeficiente de Correlação Ponto Biserial\nEsse coeficiente (\\(r_{pb}\\)) mede a correlação entre uma variável quantitativa e uma variável categórica binária (0,1). Ele pode variar entre -1 e 1 e é definido pela seguinte fórmula:\n\\(r\\_{pb} = \\dfrac{M_1-M_0}{S_n}\\sqrt{pq}\\)\n\n\\(M_1\\) = média do grupo que recebeu o valor 1 da variável binária.\n\\(M_0\\) = média do grupo que recebeu o valor 0 da variável binária.\n\\(S_n\\) = desvio padrão da variável binária toda.\n\\(p\\) = proporção de casos do grupo “0” na variável binária.\n\\(q\\) = proporção de casos do grupo “1” na variável binária."
  },
  {
    "objectID": "03-correlacao.html#correlação-linear-de-pearson",
    "href": "03-correlacao.html#correlação-linear-de-pearson",
    "title": "Análise de Correlação",
    "section": "Correlação linear de Pearson",
    "text": "Correlação linear de Pearson\nDe modo geral, a quantificação do grau de associação entre duas variáveis é feita pelos chamados coeficientes de associação ou correlação. Essas são medidas que descrevem numericamente a associação (ou dependência) entre duas variáveis. Ou seja, tais resultados nos permitem verificar se uma variável influencia de forma positiva ou negativa na outra.\nPara facilitar a compreensão, esses coeficientes usualmente variam entre -1 e +1, e quanto mais próximo de 0, menos relação as variáveis possuem. A intensidade da associação linear existente entre as variáveis quantitativas pode ser determinada através do chamado Coeficiente de Correlação Linear de Pearson, e sua fórmula é definida por:\n\\[\\rho_{(x,y)} = \\frac{cov{(x,y)}}{S_{x}S_{y}},\\] em que ,\n\n\\(\\text{Cov}{(x,y)}\\) - Covariância ou variância conjunta das variáveis X e Y;\n\\(S_{x}\\)- Desvio Padrão da variável X\n\\(S_{Y}\\) - Desvio Padrão da variável Y.\n\nComo dito anteriormente, o \\(\\rho\\) pode assumir valores entre -1 e +1 e neste ponto cabe algumas observações, tais como\n\n\\(\\rho_{(x,y)}\\) = +1 significa uma correlação positiva perfeita entre as duas variáveis, ou seja, se uma aumenta a outra também aumenta;\n\\(\\rho_{(x,y)}\\) = -1 significa uma correlação negativa perfeita entre as duas variáveis, isto é, se uma aumenta a outra diminui;\n\\(\\rho_{(x,y)}\\) = 0 significa que as duas variáveis não dependem linearmente uma da outra. No entanto, pode existir uma outra dependência “não-linear”. Logo, o resultado deve ser investigado por outros meios."
  },
  {
    "objectID": "03-correlacao.html#coeficiente-de-correlação-de-spearman",
    "href": "03-correlacao.html#coeficiente-de-correlação-de-spearman",
    "title": "Análise de Correlação",
    "section": "Coeficiente de correlação de Spearman",
    "text": "Coeficiente de correlação de Spearman\nO coeficiente de Correlação de Spearman é geralmente utilizado quando temos duas variáveis ordinais ou quando não podemos utilizar o teste Cramér V, pois não podemos facilmente atestar suas suposições. Diante de duas variáveis medidas numa escala de ordenação clara, ou que apresentam uma relação não linear mas monótona (se uma aumenta a outra tem sempre tendência a aumentar (ou a diminuir)).\nÉ um método não-paramétrico que usa os postos das variáveis quando o coeficiente de correlação de Pearson não pode ser aplicado, temos como alternativa o coeficiente de correlação de Spearman. A ideia de construção deste coeficiente é bastante simples.\nDadas duas amostras de observação ordenáveis, substitui-se cada um dos seus valores pela sua ordem de ordenação, em inglês\nPor exemplo, se uma amostra de três valores for \\(x_{1} = 2.1\\), \\(x_{2} = 1.7\\), \\(x_{3} = 4.8\\), então os respectivos ranks serão \\(r_{1}= 2\\), \\(r_{2} = 1\\), \\(r_{3} = 3\\). Após substituir cada uma das amostras pelos seus ranks o coeficiente de Spearman não e mais do que o coeficiente de Pearson aplicado agora aos . Uma vez que as ordens variam sempre entre 1 e \\(n\\) (número de observações), pode-se escrever o coeficiente do seguinte modo \\[  R_{s}=1- \\dfrac{ 6\\sum_{i=1}^{n} D_{i}^2}{n^{3} - n}, \\] onde \\(D_{i}\\) representa a diferença de ranks entre as observações que estão sendo analisadas."
  },
  {
    "objectID": "03-correlacao.html#coeficiente-tau-de-kendall",
    "href": "03-correlacao.html#coeficiente-tau-de-kendall",
    "title": "Análise de Correlação",
    "section": "Coeficiente \\(\\tau\\) de Kendall",
    "text": "Coeficiente \\(\\tau\\) de Kendall\nUma alternativa ao coeficiente de Spearman é o coeficiente de correlação \\(\\tau\\) de Kendall que se aplica nas mesmas condições, porém com duas vantagens : se as amostras tiverem dimensão muito reduzida e valores repetidos, os resultados do teste são mais precisos; por outro lado, o coeficiente \\(\\tau\\) de Kendall pode ser generalizado para correlações parciais que são correlações medidas entre duas variáveis após remoção do efeito de uma possível terceira variável sobre ambas.\nO coeficiente de Kendall é descrito como uma medida de concordância entre dois conjuntos, medindo a diferença entre a probabilidade de as classificações estarem na mesma ordem e a probabilidade de estarem em ordens diferentes.\n\\[ \\tau = \\dfrac{ concordantes - discordantes}{\\frac{n(n-1)}{2}}.   \\]"
  },
  {
    "objectID": "04-inferencia.html#teste-de-hipóteses",
    "href": "04-inferencia.html#teste-de-hipóteses",
    "title": "1  Inferência",
    "section": "1.1 Teste de Hipóteses",
    "text": "1.1 Teste de Hipóteses\n\n1.1.1 Definição\nUm teste de hipóteses estatístico é um procedimento que utilizamos para testar duas hipóteses disjuntas a respeito de um parâmetro de interesse. Utiliza-se a nomenclatura \\(H_0\\) e \\(H_1\\) para representar as hipóteses, as quais são chamadas de “hipótese nula” e “hipótese alternativa”, respectivamente.\nQuando testamos uma hipótese, podemos encontrar dois tipos de erros: - Erro Tipo I: Consiste em rejeitarmos a hipótese nula, dado que ela é vera dadeira. Geralmente, representa-se por \\(\\alpha\\) a probabilidade de cometer esse tipo de erro. - Erro Tipo II: Consiste em não rejeitarmos \\(H_0\\), dado que ela é falsa. Normalmente representa-se com a letra grega \\(\\beta\\) a probabilidade de cometer esse erro.\nAmbos os erros devem ser evitados, porém, por questões matemáticas, geralmente só podemos controlar facilmente o Erro Tipo I, por isso, devemos estabelecer as hipóteses de forma que o Erro Tipo I seja o erro mais prejudicial ao processo estudado.\nNível de significância: O valor de \\(\\alpha\\), referente ao Erro Tipo I, é chamado de nível de significância, esse valor deve ser pré-estabelecido pelo pesquisador.\nEstatística de teste: É a estatística amostral na qual basearemos seus valores para decidirmos pela rejeição ou não de \\(H_0\\). Essa estatística é associada ao estimador do parâmetro que se deseja testar. Por exemplo, ao queremos testar algo sobre o real valor da média populacional \\(\\mu\\) (parâmetro),quando conhece-se o valor do desvio padrão populacional (\\(\\sigma\\)) utiliza-se a a estatística de teste abaixo:\n\\(Z = \\dfrac{\\bar{X}-\\mu}{\\sigma/\\sqrt n}\\) Onde: \\(\\bar{X}\\) é a média amostral, sendo ela o estimador natural da média populacional; n é o tamanho da nossa amostra.\nRegião de Rejeição: É a região formada pelo conjunto de valores que levam \\(H_0\\) a ser rejeitada. O valor que delimita essa região é denominado valor crítico. Caso o valor calculado da estatística de teste caia nessa região, rejeita-se a hipótese nula.\nNível descritivo ou valor-p: É o menor valor para o qual rejeita-se a hipótese nula. Quando esse valor cai na região crítica, rejeita-se \\(H_0\\). Para sabermos se rejeitaremos ou não \\(H_0\\) baseado no valor-p, deve-se compará-lo com o nível de significância do teste e rejeitar \\(H_0\\), se aquele for menor do que este, rejeita-se \\(H_0\\)."
  },
  {
    "objectID": "04-inferencia.html#testes-de-independência",
    "href": "04-inferencia.html#testes-de-independência",
    "title": "1  Inferência",
    "section": "1.2 Testes de Independência",
    "text": "1.2 Testes de Independência\nComo em todo teste de hipóteses, devemos estabelecer primeiro as hipóteses a serem testadas. Num teste de independência essas hipóteses são:\n\nH_0: As variáveis de classificação são independentes.\nH_1: As variáveis de classificação não são independentes.\n\nExistem vários testes de independência em que cada um desses são adequados para uma determinada situação"
  },
  {
    "objectID": "04-inferencia.html#teste-t-para-amostras-independentes",
    "href": "04-inferencia.html#teste-t-para-amostras-independentes",
    "title": "1  Inferência",
    "section": "1.3 Teste T para amostras independentes",
    "text": "1.3 Teste T para amostras independentes\nO teste T é utilizado para verificar a existência de diferença entre as médias de dois grupos da mesma população. Para isso a variável independente deve ser necessariamente métrica e a variável dependente deve ser categórica.\nSuponha que o objetivo seja analisar as médias amostrais \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\)\nAssim, testa-se a hipótese como segue:\n\\[\\begin{cases} H_0: \\bar{x}_1 = \\bar{x}_2 \\\\ H_1: \\bar{x}_1 \\neq \\ \\bar{x}_2 \\end{cases}\\]\nSuponha que o objetivo seja analisar as médias amostrais \\(\\bar{x}_1\\) e \\(\\bar{x}_2\\)\n\\[t = \\frac{\\bar{x}_1-\\bar{x}_2}{\\sqrt{s^2(\\frac{1}{n_1}+\\frac{1}{n_2})}}\\]\nOnde o numerador é a diferença das médias amostrais e o denominados é o desvio padrão amostral"
  },
  {
    "objectID": "04-inferencia.html#teste-exato-de-fisher",
    "href": "04-inferencia.html#teste-exato-de-fisher",
    "title": "1  Inferência",
    "section": "1.4 Teste Exato de Fisher",
    "text": "1.4 Teste Exato de Fisher\nO Teste Exato de Fisher é utilizado para verificar se existe associação entre as variáveis linha e as variáveis coluna em uma tabela de contingência construída a partir dos dados da amostra. Embora na prática o Teste Exato de Fisher seja aplicado quando os tamanhos das amostras são pequenos, o teste é válido para todos os tamanhos amostrais.\nAs hipóteses do teste são:\n\\[\\begin{cases}\nH_0: \\text{As variáveis linha e coluna são independentes}; \\\\\nH_1: \\text{As variáveis linha e coluna não são independentes.}\n\\end{cases}\\]\nA estatística de teste, apresentada por Fisher (1934), propõe que a distribuição de probabilidade das frequências de quaisquer tabelas de contingência sejam substituídas pela probabilidade da distribuição das mesmas frequências. Considerando a Tabela \\(\\ref{eq:exemplo}\\), arranjada de modo que \\(n_{1.}\\leq n_{.1}\\leq n_{.2}\\leq n_{2.}\\), temos uma distribuição de probabilidade hipergeométrica para a única frequência de valor independente, \\(o_{11}\\), a partir de,\n\\[P[X=o_{11}]=\\cfrac{\\displaystyle{n_{1.} \\choose o_{11}} \\displaystyle{n_{2.} \\choose o_{21}}}{\\displaystyle{n \\choose n_{.1}}}=\\cfrac{n_{1.}!n_{2.}!n_{.1}!n_{.2}!}{o_{11}!o_{12}!o_{21}!o_{22}!n!}\\]\nO Teste Exato de Fisher consiste na determinação desta probabilidade e dos arranjos possíveis que, com os mesmos totais marginais, tenham ainda mais desvios em relação à hipótese nula \\(H_0\\)."
  },
  {
    "objectID": "04-inferencia.html#teste-de-bonferroni",
    "href": "04-inferencia.html#teste-de-bonferroni",
    "title": "1  Inferência",
    "section": "1.5 Teste de Bonferroni",
    "text": "1.5 Teste de Bonferroni\nO teste de bonferroni consiste na realização de um teste t para cada par de médias a uma taxa de erro por comparação (TPC) de \\(a/(k/2)\\). Usando esse teste, o nível de significância da família é no máximo \\(a\\), para qualquer média das populações. Assim o teste de Bonferroni protege a taxa de erro da família dos testes. Pode ser usado para quaisquer que sejam os dados balanceados ou não. Não é um teste exato, e assim é baseado na aproximação como primeira desigualdade de Bonferroni. Em diversos momentos ele pode ser um teste conservativo, isto é, a taxa de erro da família testes é muito menor que o nível de significância \\(a\\). Para tamanhos de amostras iguais o teste de Bonferroni considera duas médias significativamente diferentes se o valor absoluto das diferenças ultrapassar: $ LSD=t_{(a,N-k)} $ E para os dados não balanceados temos:\n$ LSD=t_{(a,N-k)} $\nEm que \\(a^\\prime=\\frac{1}{2}(a/c)\\) e c é o número de comparações duas a duas. O quantil \\(t_{(a,N-k)}\\) é da distribuição t-Student com parâmetros \\(N-k\\). Assim a margem de erro da equação anterior depende do número de comparações."
  },
  {
    "objectID": "04-inferencia.html#teste-de-proporção",
    "href": "04-inferencia.html#teste-de-proporção",
    "title": "1  Inferência",
    "section": "1.6 Teste de Proporção",
    "text": "1.6 Teste de Proporção\nTemos que testar hipóteses e construir intervalos de confiança para a proporção de uma população. Supondo que uma amostra aleatória de tamanho n tenha sido retirada de uma grande população e que X são as observações, nessa amostra pertencem a uma classe de interesse. Então \\(P=X/n\\) é um estimador da proporção \\(p\\) da população, que pertence a essa classe, \\(n\\) e \\(p\\) são parâmetros da Distribuição Binomial.,em que \\(n\\) é o tamanho amostral e \\(p\\) a proporção. Para o teste bilateral:\n\\[\\begin{cases}\n  H_0: p=p_0\\\\\n  H_1: p \\neq p_0\n  \\end{cases}\\]\nA estatística de teste é: \\[Z_0=\\frac{X-np_0}{\\sqrt{nX/n(1-X/n)}}\\] Rejeitamos a hipótese nula se\n\\[ Z_0&lt;- Z_{1-\\alpha/2} \\,\\text{ ou }\\, Z_0 &gt; Z_{1-\\alpha/2} \\]\nPara o teste unilateral a direita:\n\\[\\begin{cases}\n  H_0: p=p_0\\\\\n  H_1: p &gt; p_0\n  \\end{cases}\\]\nA estatística de teste é: \\[Z_0=\\frac{X-np_0}{\\sqrt{nX/n(1-X/n)}}\\] Rejeitamos a hipótese nula se \\[ Z_0 &gt; Z_{1-\\alpha} \\]"
  },
  {
    "objectID": "04-inferencia.html#teste-de-post-hoc",
    "href": "04-inferencia.html#teste-de-post-hoc",
    "title": "1  Inferência",
    "section": "1.7 Teste de Post Hoc",
    "text": "1.7 Teste de Post Hoc\nAnálise Post Hoc é feita após a conclusão do estudo, usando o tamanho do estudo e de efeito obtidos para determinar a potência da amostra estudada, podemos dizer que são conjuntos de teste para determinar as diferenças presentes. Os testes são para comparações pareadas, projetadas afim de comparar todas as diferentes combinações dos grupos de tratamento. Observando as taxas erro, temos:\n\nErro tipo 1: É a probabilidade de rejeitar a hipótese nula (Ho), quando ela é verdadeira.\nErro tipo 2: É a probabilidade de não rejeitar a hipótese nula (Ho), quando ela é falsa.\n\nProbabilidade de acontecer pelo menos um erro do Tipo I em um conjunto de relações estatísticas, assumindo erroneamente que pelo menos uma das diferenças analisadas é significativamente diferente da hipótese nula.\n\\(\\alpha_{F_W}= 1-(1- \\alpha)^c\\) Onde C é o número de comparações, então dessa forma temos que:\n\\[ c=\\frac{k*(k-1)}{2}\n\\]"
  },
  {
    "objectID": "04-inferencia.html#teste-de-mcnemar",
    "href": "04-inferencia.html#teste-de-mcnemar",
    "title": "1  Inferência",
    "section": "1.8 Teste de McNemar",
    "text": "1.8 Teste de McNemar\nO teste de McNemar é utilizado em tabelas de contingência, essencialmente em tabelas \\((2\\times2)\\), com dados pareados para comparar frequências marginais, que em outras palavras significa que o teste compara se houve mudança nas proporções no objeto de estudo antes e depois de uma intervenção.\nAs hipóteses do teste são:\n\\[\\begin{cases}\nH_0: \\text{As variáveis linha e coluna possuem as mesmas proporções;}\\\\\nH_1: \\text{As variáveis linha e coluna possuem proporções diferentes.}\n\\end{cases}\\]\nA estatística do teste, \\(Q\\), é dada por: \\[ Q=\\cfrac{(a-d)^2}{(a+d)}\\] em que \\(Q \\sim \\chi^2(1)\\), lê-se \\(Q\\) segue uma distribuição qui-quadrado com 1 grau de liberdade."
  },
  {
    "objectID": "04-inferencia.html#teste-de-wilcoxon-pareado",
    "href": "04-inferencia.html#teste-de-wilcoxon-pareado",
    "title": "1  Inferência",
    "section": "1.9 Teste de Wilcoxon pareado",
    "text": "1.9 Teste de Wilcoxon pareado\nO teste de Wilcoxon pareado é utilizado para comparar se dois grupos possuem a mesma medida de tendência central. Esse teste leva em consideração a magnitude das diferenças entre os pares.\nSeja \\(d_i\\) o escore-diferença para qualquer par combinado, representando a diferença dos pares sobre dois tratamentos \\(X\\) e \\(Y\\), isto é, \\(d_i=X_i-Y_i\\). Ordena-se todos os \\(d_i\\)’s sem considerar o sinal, posteriormente dar-se o posto 1 ao menor \\(|d_i|\\), posto 2 ao segundo menor, e assim sucessivamente.\nAs possíveis hipóteses do teste são:\n\n\\(H_0\\): \\(d=0\\) vs \\(H_1\\): \\(d \\neq 0\\);\n\\(H_0\\): \\(d=0\\) vs \\(H_1\\): \\(d&gt;0\\);\n\\(H_0\\): \\(d=0\\) vs \\(H_1\\): \\(d&lt;0\\).\n\nA hipótese nula (\\(H_0\\)) é que os tratamentos \\(X\\) e \\(Y\\) são equivalentes, isto é, eles são amostras de populações com a mesma mediana e a mesma distribuição contínua.\nDuas estatísticas são definidas: \\[\n    T^+=\\sum_{i}d_i,\n\\] \\[\n    T^-=\\sum_{i}d_i,\n\\]\nsoma dos \\(d_i\\)’s positivos e soma dos \\(d_i\\)’s negativos, respectivamente.\nRejeitamos a hipótese nula se a probabilidade de \\(T^+\\) tabulado para um determinado tamanho \\(N\\) é menor ou igual ao nível de significância escolhido."
  },
  {
    "objectID": "04-inferencia.html#teste-qui-quadrado",
    "href": "04-inferencia.html#teste-qui-quadrado",
    "title": "1  Inferência",
    "section": "1.10 Teste Qui-Quadrado",
    "text": "1.10 Teste Qui-Quadrado\n\n1.10.1 Teste Qui-Quadrado de Pearson para independência\nO teste de independência Qui-Quadrado é usado para descobrir se existe uma associação entre a variável de linha e a variável de coluna em uma tabela de contingência construído à partir de dados da amostra. A hipótese nula é de que as variáveis não estão associadas, em outras palavras, eles são independentes. A hipótese alternativa é de que as variáveis estão associadas, ou dependentes.\nPara que o teste possa ser aplicado, é necessário levar em consideração algumas suposições e condições, que serão listadas a seguir:\n\nOs dados devem ser derivados de contagens(frequências) para as categorias das variáveis categóricas;\nAs frequência das células da tabela de dupla entrada devem ser independentes umas das outras;\nOs sujeitos contados na tabela devem ser de uma amostra aleatória extraída de uma única população;\nDevemos ter dados suficientes;\nA tabela de contingência(dupla entrada) deve conter pelo menos 5 observações em cada célula;\nA tabela de valores esperados não pode conter observações menores que 5\nO teste é aplicável tanto para a variável qualitativa quanto quantitativa.\n\nAs hipóteses do teste são:\n\\[\\begin{cases} H_0: \\text{As variáveis X e Y são independentes};\\\\ H_1: \\text{As variáveis X e Y não são independentes.} \\end{cases}\\]\nA Estatística do teste é dada por:\n\\[\\chi^2 = \\sum_i\\sum_j\\frac{(o_{ij} - e_{ij}^2)}{e_{ij}}\\]\nonde: - \\(o_{ij}\\) é o valor observado na célula; - \\(e_{ij}\\) é o valor esperado - \\(e_{ij} = \\frac{\\text{total da linha i} * \\text{total da coluna j}}{\\text{total geral}}\\)\nRejeitamos \\(H_0\\) se \\(\\chi^2_{calculado} &gt; \\chi^2_{tabelado}\\)\n\n\n1.10.2 Teste Qui-Quadrado\nO teste \\(\\chi^2\\) ( Qui- Quadrado) é um dos testes usados para avaliar se há independência entre variáveis qualitativas, para isso, devemos dispor nossos dados em uma tabela de contingência, no caso em que queremos testar a hipótese de independência entre exatamente duas variáveis, utiliza-se uma tabela de dupla entrada.\nPara realizar o teste, iremos testar a hipótese como segue: $\n\\[\\begin{cases} H_0: \\text{As variáveis são independentes;} \\\\ H_1: \\text{As variáveis não são independentes.} \\end{cases}\\]\nPara isso, utilizaremos a estatística de teste abaixo:\n\\(\\mathbf{\\chi^2_v} = \\dfrac{\\sum_{\\substack{i=1}}^{k} \\sum_{\\substack{i=1}}^{l}(O_{ij}-E_{ij})^2}{E_{ij}}\\)\nonde:\nk é o número de linhas da tabela ;\nl é o número de colunas;\n\\(E_{ij} = n p_{ij}\\) é a frequência esperada da célula ij;\n\\(p_{ij}\\) é a probabilidade de ocorrer uma observação na célula ij. Se as variáveis são independentes, espera-se que \\(p_{ij} = p_{i.}p_{j.}\\), onde \\(p_i{i.}\\) é a probabilidade marginal correspondente a linha i e \\(p_{.j}\\) é a probabilidade marginal correspondente a coluna j;\n\\(v = (k-1)(l-1)\\) é o grau de liberdade.\nAssim como nos demais testes de hipóteses, rejeitaremos \\(H_0\\) caso a probabilidade encontrada seja menor do que o nível de significância estipulado.\nPorém, esse teste apresenta problemas quando temos um número de observações considerado pequeno - geralmente considera-se “pequeno” um tamanho amostral menor do que 40 unidades - ou quando temos em uma das caselas de cruzamento um número esperado menor do que 5. Nesses casos, utiliza-se uma correção para uma melhor estimação.\nA correção indicada para esse caso é a de Yates ou de Continuidade, pela qual o valor do teste Qui-Quadrado será recalculado como se segue:\n\\(\\mathbf{\\chi^2_v} = \\dfrac{\\sum_{\\substack{i=1}}^{k} \\sum_{\\substack{i=1}}^{l}(|O_{ij}-E_{ij}|-0,5)^2}{E_{ij}}.\\)"
  },
  {
    "objectID": "08-amostragem.html#amostragem-aleatória-simples-sem-reposição---aass",
    "href": "08-amostragem.html#amostragem-aleatória-simples-sem-reposição---aass",
    "title": "5  Amostragem",
    "section": "5.7 Amostragem Aleatória Simples sem reposição - AASs",
    "text": "5.7 Amostragem Aleatória Simples sem reposição - AASs\nPara a confecção desse trabalho foi utilizada amostragem aleatória simples sem reposição, uma vez que o espaço amostral era composto por idosos que são acompanhados pelo posto de saúde, ou seja, o mesmo idoso é acompanhado por apenas um posto de saúde. Levou-se em consideração que cada idoso poderia ou não ser selecionado, perante isso, utiliza-se na Estatística a distribuição de Bernoulli. Sendo \\(x_i\\) o idoso observado, então:\n$x_i = \\begin{cases} 1, \\ 0, $\nDe acordo com a distribuição assumida, pode-se calcular a variância dos dados por:\n\\[\\sigma^2 = p(1 - p),\\]\nem que:\n\\(\\sigma^2 =\\) Variabilidade dos indivíduos na nossa população;\n\\(p =\\) Proporção de membros da população em estudo que apresenta a característica.\nComo não teve-se acesso a nenhum dado anterior que pudesse estimar a variabilidade dos dados estudados, tais como pesquisas anteriores, optou-se por usar a maior variabilidade possível, denotada na estatística como “variabilidade conservadora”, no qual \\(p\\) assume o valor que maior estima a variância, no caso, 0,5. Daí, segue-se que,\n\\[S^2 = p(1 - p) = 0,5(1 - 0,5) = 0,25 = \\frac{1}{4},\\]\nonde \\(S^2\\) é a variância estimada.\nDiante tudo isso, calcula-se o tamanho amostral, denotado por \\(n\\), através da seguinte expressão:\n\\[n = \\frac{1}{\\frac{D}{S^2}+\\frac{1}{N}},\\]\nem que:\n\\(D \\ = \\frac{E^2}{Z_\\alpha};\\)\n\\(E \\ =\\) Erro máximo permitido;\n\\(Z_\\alpha =\\) Quantil de ordem \\(\\alpha\\) da distribuição normal padrão;\n\\(N \\ =\\) Tamanho populacional;\n\\(S^2 =\\) Variância populacional estimada.\nO Erro máximo permitido ou margem de erro é a diferença entre o valor estimado pela pesquisa e o verdadeiro valor. Por exemplo, se retirarmos a média \\(\\mu\\) de uma amostra com uma margem de erro de 10% esperamos que a média da população esteja em um intervalo de \\(\\mu - 10\\%\\) e \\(\\mu + 10\\%\\). Para estimarmos uma determinada característica de interesse com dada precisão, é importante que estabeleçamos um nível de confiança para nossa pesquisa, nível esse que denotaremos por \\((1 - \\alpha)\\), sendo a probabilidade de que o erro amostral efetivo seja menor do que o erro amostral admitido pela pesquisa (máximo permitido). É importante salientar que um alto nível de confiança pode trazer problemas atrelados a ele, por exemplo, uma necessidade de um maior tamanho amostral.\nMargem de erro, Coeficiente de confiança e tamanho da amostra sempre caminham lado a lado. Modificar qualquer um dos 3 parâmetros, alterará os restantes. Encontra-se algumas mudanças:\n\nReduzir a margem de erro obriga a aumentar o tamanho da amostra;\nDiminuir o Coeficiente de confiança obriga a aumentar o tamanho da amostra;\nSe eu aumentar o tamanho da minha amostra, posso reduzir a margem de erro ou incrementar o nível de confiança.\n\nExiste casos onde o tamanho amostral fica inacessível para o pesquisador devido aos custos gerados, para isto existe um fator de correção para diminuir o tamanho amostral (n), quando \\(\\frac{n}{N} \\geq 0,05\\). Segue o novo tamanho amostral:\n\\[n_{new} = \\frac{n}{1 + \\left(\\frac{n - 1}{N}\\right)}\\]\nem que:\n\\(n_{new} =\\) Novo tamanho amostral com fator de correção;\n\\(n =\\) Tamanho amostral sem o fator de correção;\n\\(N =\\) Tamanho da população alvo."
  },
  {
    "objectID": "05-nao_parametrica.html#teste-de-wilcoxon-mann-whitney",
    "href": "05-nao_parametrica.html#teste-de-wilcoxon-mann-whitney",
    "title": "2  Estatística Não-Paramétrica",
    "section": "2.1 Teste de Wilcoxon-Mann-Whitney",
    "text": "2.1 Teste de Wilcoxon-Mann-Whitney\n\n2.1.1 Definição 1\nProposto inicialmente por Frank Wilcoxon (1945) e com contribuições de Henry B. Mann e Donald R. Whitney (1947), o teste de Wilcoxon-Mann-Whitney é um teste não paramétrico aplicado em duas amostras independentes.\nEsse teste é baseado nos postos dos valores obtidos combinando-se as duas amostras. Isso é feito ordenando-se esses valores, do menor para o maior, independentemente do fato de qual população cada valor provém, caso haja observações repetidas atribui-se a média dos postos correspondentes. O teste de Wilcoxon-Mann-Whitney tem como objetivo testar se as distribuições possuem a mesma medida de tendência central.\nSeja \\(X_1\\), \\(X_2\\), …, \\(X_m\\) uma amostra aleatória de \\(X\\) de modo que \\(X_j\\)’s são independentes e identicamente distribuídos e \\(Y_1\\), \\(Y_2\\), …, \\(Y_n\\) uma amostra aleatória de \\(Y\\) de modo que os \\(Y_i\\)’s são independentes e identicamente distribuídos. Além disso, suponha que os \\(X_j\\)’s e os \\(Y_i\\)’s são mutuamente independentes e a amostra \\(Y\\) aquela com o menor tamanho amostral, isto é, \\(n \\leq m\\).\nAs possíveis hipóteses do teste são:\n\n\\(H_0\\): \\(\\Delta=0\\) vs \\(H_1\\): \\(\\Delta\\neq0\\);\n\\(H_0\\): \\(\\Delta=0\\) vs \\(H_1\\): \\(\\Delta&gt;0\\);\n\\(H_0\\): \\(\\Delta=0\\) vs \\(H_1\\): \\(\\Delta&lt;0\\).\n\nem que:\n\n\\(\\Delta\\) = Estimador da diferença das posições.\n\nPara estimar a diferença \\(\\Delta\\) entre as medianas das populações, consideramos todas as \\(m \\times n\\) diferenças \\(y_i - x_j\\) ordenadas de forma crescente.\nO estimador \\(\\hat{\\Delta}\\) associado a estatística de Wilcoxon-Mann-Whitney é definido por \\(\\hat{\\Delta}= \\ \\hbox{mediana}\\{(y_i-x_j), \\ i=1,\\ldots, n; j=1,\\ldots,m\\}\\), chamado de pseudo-mediana.\nA estatística de teste, denotada por \\(W\\), é dada pelo mínimo de \\(U_m\\) e \\(U_n\\)\n\\[\\begin{align*}\n    U_m &= S_m - \\frac{m(m+1)}{2} \\\\\n    U_n &= S_n - \\frac{n(n+1)}{2}\n\\end{align*}\\]\nem que:\n\n\\(S_m\\) = Soma dos postos relacionados a amostra \\(X\\);\n\\(S_n\\) = Soma dos postos relacionados a amostra \\(Y\\).\n\n\n\n2.1.2 Definição 2 :\nO teste de Wilcoxon-Mann-whitney é um teste não-paramétrico, ou seja, é um teste usado quando temos poucas ( ou nenhuma) evidências sobre a real distribuição dos dados. Ele se utiliza de passos idênticos aos que usamos para calcular um teste de hipóteses usual.\nSeja \\(P_1\\) e \\(P_2\\) duas população das quais não temos informações sobre suas distribuições, porém, temos que seus dados são qualitativo ordinais ou quantitativos. Retira-se uma amostra de cada uma dessas populações, sendo essas independentes. O procedimento utilizado nesse teste consiste em ordenarmos essas duas amostras de forma combinada, ou seja, ordena-se esses valores sem a necessidade de levar em consideração de qual população o dado provém. Com isso, testaremos se as duas populações têm a mesma mediana, ou seja, se suas distribuições são iguais em localização.\nSendo \\(X_1,X_2,...,X_m\\) e \\(Y_1,Y_2,...,Y_n\\), amostras aleatórias independentes e identicamente distribuídas(i.i.d) das populações \\(P_1\\) e \\(P_2\\), respectivamente. Além disso, essas amostras também serão independentes entre si, sendo essas tomadas de forma que \\(n\\leq m\\).\nSendo F e G as funções de distribuição correspondentes as populações \\(P_1\\) e \\(P_2\\), respectivamente, a hipótese nula é tal como segue: \\(H_0: F(t) = G(t),\\text{para todo t}\\)\nEntretanto, podemos também considerar que Y tem a mesma distribuição de X+\\(\\Delta\\). Perante isso, a hipótese nula será:\n\\(H_0: \\Delta = 0\\)\nDaí, como estamos interessados apenas em haver diferença entre as medianas, independentemente se essa diferença é negativa ou positiva, utilizamos como hipótese alternativa, uma hipótese bilateral, como vemos abaixo:\n\\(H_1: \\Delta \\neq 0\\)\nCom os dados já ordenados em ordem crescente, calculamos \\(S_m\\) e \\(S_n\\), que serão as somas dos postos de X e Y , respectivamente. Após isso, obteremos:\n\\(U_m = S_m - \\dfrac{1}{2}m(m+1);\\) e ;$ U_n = S_n - n(n+1)$\nApós isso, calcula-se a estatistica de teste W, que será o menor valor entre \\(U_m\\) e \\(U_n\\).\nSob \\(H_0\\), espera-se que tenhamos uma distribuição de postos aproximadamente igual, daí, o posto médio das duas amostras deve ser parecido.\nDaí,deve-se encontrar os valores críticos \\(t_1\\) e \\(t_2\\), de forma que\n\\(P(W&lt;t_1\\) = \\(P(W&gt;t_2) \\approx \\dfrac{\\alpha}{2}\\)\nRejeita-se \\(H_0\\) caso \\(W_{obs}&lt;t_1\\) ou \\(W_{obs}&gt;t_2\\)\nSeu valor-p será dado por: $ 2P(W&gt;W_{obs}-1,$ se \\(W_{obs}&gt;\\dfrac{mn}{2}\\) ou \\(2P(W&lt;W_{obs})\\), se \\(W\\_{obs}\\leq \\dfrac{mn}{2}\\)"
  },
  {
    "objectID": "06-regressao.html#modelos-de-regressão",
    "href": "06-regressao.html#modelos-de-regressão",
    "title": "3  Regressão",
    "section": "3.1 Modelos de Regressão",
    "text": "3.1 Modelos de Regressão\nEm diversos estudos é de extrema importância verificar se duas ou mais variáveis estão relacionadas entre si. Uma alternativa é determinar um modelo matemático que expresse tal relação, e na estatística este tipo de análise é conhecido como: Análise de Regressão. Em outras palavras, modelos de regressão nos ajudam a compreender melhor como uma variável influência no comportamento de outras.\nCaso o interesse da pesquisa seja avaliar a relação da variável dependente (expressa por \\(Y\\)) com apenas uma variável independente (\\(X\\)), estamos lidando com Regressão Linear Simples. Porém, se for necessária a verificação de duas ou mais variáveis independentes, temos um caso de Regressão Linear Múltipla.\nOs modelos de regressão múltipla são construídos pelos seguintes passos:\n\nSeleção de variáveis: a priori, não sabemos quais são as variáveis independentes que influenciam de forma mais significativa na variável resposta (dependente). O objetivo é encontrar um modelo mais parcimonioso que explica os dados, porém quanto mais variáveis no modelo, maior se torna a estimativa do erro e mais dependente o modelo fica dos dados observados. Então, devemos checar a importância das variáveis, incluindo ou excluindo-as do modelo se baseando em uma regra de decisão. Para esta seleção utiliza-se a relação das variáveis preditoras (inpedendentes) com a variável resposta (dependente), analisando sempre a relação de cada variável incluída, observando a significância da mesma.\nEstimação dos parâmetros: a estimação dos parâmetros significa obter valores (estimativas) para os mesmos, para que possamos incluir esses resultados no modelo.\n\n3.Análise residual ou diagnóstico: auxilia no ajuste final do modelo, identificando observações que influênciam na estimação dos parâmetros e/ou mudança na reta dos ajustados."
  },
  {
    "objectID": "06-regressao.html#coeficiente-de-determinação",
    "href": "06-regressao.html#coeficiente-de-determinação",
    "title": "3  Regressão",
    "section": "3.2 Coeficiente de Determinação",
    "text": "3.2 Coeficiente de Determinação\nUma das formas de avaliar a qualidade do ajuste do modelo é através do coeficiente de determinação, representado por \\(R^2\\). Este varia entre \\(0\\leq R^2 \\leq 1\\) e indica quanto o modelo foi capaz de explicar os dados coletados. Vale ressaltar que é pouco comum que tenhamos uma correlação perfeita (\\(R^2=1\\)) na prática, porque existem muitos fatores que determinam as relações entre variáveis na vida real. O coeficiente de determinação é dado pela seguinte expressão\n\\[\\begin{eqnarray*}\nR^2=\\dfrac{\\bigg(\\sum_{i=1}^n (x_i-\\bar{x})Y_i\\bigg)^2}{\\sum_{i=1}^n (x_i - \\bar{x})^2 \\sum_{i=1}^n (Y_i - \\bar{Y})^2}\n\\end{eqnarray*}\\]"
  },
  {
    "objectID": "06-regressao.html#transformação-de-yeo-johnson",
    "href": "06-regressao.html#transformação-de-yeo-johnson",
    "title": "3  Regressão",
    "section": "3.3 Transformação de Yeo-Johnson",
    "text": "3.3 Transformação de Yeo-Johnson\nExistem situações que a variável em estudo não possui comportamento normal e para o uso da regressão linear múltipla é necessário que a suposição de normalidade seja cumprida. Uma alternativa em experimentos como esse é o uso de alguma transformação na variável resposta.\nA transformação de Box-Cox (1964) é amplamente utilizada, contudo essa transformação é válida apenas em variáveis positivas. Uma alternativa de transformação para variáveis que assumem valores positivos e negativos é a transformação de Yeo-Johnson (2000), essa é uma extensão da transformação de Box-Cox. Sua fórmula é definida a seguir\n\\[\\begin{eqnarray*}\n\\phi^{(\\lambda)}=\\left\\{\\begin{array}{rc}\n\\dfrac{(y+1)^\\lambda-1}{\\lambda},&\\mbox{para }\\lambda \\neq0, y \\geq 0\\\\\n\\text{log}(y+1), &\\mbox{para } \\lambda =0 , y\\geq 0 \\\\\n-\\dfrac{(1-y)^{2-\\lambda}-1}{2-\\lambda},  &\\mbox{para } \\lambda \\neq2 , y &lt; 0 \\\\\n-\\text{log}(1-y), &\\mbox{para } \\lambda =2 , y &lt; 0\n\\end{array}\\right.\n\\end{eqnarray*}\\]\nem que \\(\\lambda\\) é um parâmetro desconhecido e \\(\\phi^{(\\lambda)}\\) é a observação transformada."
  },
  {
    "objectID": "06-regressao.html#análise-de-regressão-linear-e-correlação",
    "href": "06-regressao.html#análise-de-regressão-linear-e-correlação",
    "title": "3  Regressão",
    "section": "3.4 Análise de Regressão Linear e Correlação",
    "text": "3.4 Análise de Regressão Linear e Correlação\nA análise de regressão linear consiste em estudar a relação de uma variável dependente(variável resposta) e variáveis independentes(variáveis de regressão), essas variáveis são denominadas variável \\(y\\) e \\(x\\), respectivamente, e essa relação é expressa na forma funcional abaixo descrita a seguir:\n\\[Y = \\beta_{0} + \\beta_{1} X_{1} + \\ldots + \\beta_{p} X_{n}\\]\nEscrever a variável resposta em função da(s) variável(eis) \\(x\\) implica dizer que existe uma relação linear entre elas. Cada coeficiente do modelo é estimado por meio do método de máxima verossimilhança, o qual obtém-se estimadores com boas propriedades. Quanto a adequabilidade do modelo pode-se testar a partir da análise de variância (ANOVA) se o modelo é adequado ou não. Para isso as hipóteses testadas são\n\\[\n\\begin{cases}\nH_0: \\beta_{0} = \\beta_{1} = \\ldots = \\beta_{p} = 0; \\\\\nH_1: \\text{Pelo menos um} \\; \\beta_{j} \\; \\text{é diferente de zero.}\n\\end{cases} \\]\nA estatística F é usada para testar essas hipóteses. Tomando a seguinte regra de decisão se a estatística \\(F_{calculada} &gt; F_{tabelada}\\) rejeita-se a hipótese \\(H_{0}\\). Ou se o valor-p for obtido no teste for menor que o alfa de \\(5\\%\\).\nRejeitar a hipótese \\(H_{0}\\) significa que as co-variáveis são significativas para explicar linearmente a variável resposta."
  },
  {
    "objectID": "06-regressao.html#análise-de-variância-multivariada",
    "href": "06-regressao.html#análise-de-variância-multivariada",
    "title": "3  Regressão",
    "section": "3.5 Análise de Variância Multivariada",
    "text": "3.5 Análise de Variância Multivariada\n\n3.5.1 (ANOVA) Análise de variância\nAssim como o teste t, essa técnica estatística compara a média de grupos, entretanto, enquanto o teste t focaliza em dois grupos, por outro lado, a ANOVA compara três ou mais grupos e, adicionalmente, assume que as variâncias são iguais em todos os grupos (homocedasticidade).\nA fim de testar a igualdade das médias, utiliza-se a seguinte estatística de teste:\n\\[F = \\frac{S^2_{entre}}{S^2_{dentro}}\\]\nOnde o numerador é a variância entre os grupos e o denominador a variância dentro dos grupos para \\(k-1\\) e \\(n - k\\) graus de liberdade, respectivamente, em que \\(k\\) é o número de grupos e \\(n\\) o número de observações.\n\n\n3.5.2 MANOVA\nA análise de variância multivariada (MANOVA) é uma forma generalizada da análise de variância (ANOVA). É utilizada em casos onde existem duas ou mais variáveis dependentes. A ferramenta MANOVA permite comparar se há diferença entre os tratamentos para as variáveis respostas. É utilizada a estatística Wilks para testar a igualdade entre os tratamentos, as hipóteses do teste são\n\\[\\begin{cases}\n  H_0: \\mu_{1}=\\mu_{2}=\\ldots=\\mu_{k};    \\\\\n  H_1: \\text{pelo menos duas são diferentes.}\n\\end{cases}\n\\]\nem que \\(\\mu\\_{i}\\) , \\(i = 1,2,\\ldots,k\\) são as médias dos tratamentos. A estatística \\(\\Lambda^{*}\\) foi originalmente proposta por Wilks e corresponde a uma forma equivalente do teste F da hipótese de ausência de efeito de tratamento do caso uni-variado. Que é dada por:\n\\[ \\Lambda^{*} = \\dfrac{|E|}{|H|+|E|}\\]\nOnde, o determinante da soma do quadrado dos erros e dos produtos cruzados, a matriz W é dividida pelo determinante da soma total de quadrados e matriz de produtos cruzados T = H + E. Se H é grande em relação a E, então | H + E | será grande em relação a | E |. Assim, vamos rejeitar a hipótese nula quanto menor for a estatística de Wilks (perto de zero)."
  },
  {
    "objectID": "06-regressao.html#regressão-linear-múltipla",
    "href": "06-regressao.html#regressão-linear-múltipla",
    "title": "3  Regressão",
    "section": "3.6 Regressão Linear Múltipla",
    "text": "3.6 Regressão Linear Múltipla\nPodemos definir um modelo de regressão linear múltipla da seguinte maneira:\n\\[\\begin{eqnarray*}\nY= \\beta_0 + \\boldsymbol{\\beta}_j\\boldsymbol{X}_j+\\boldsymbol{\\varepsilon}_i,\\ i=1,...,n,\n\\end{eqnarray*}\\]\nem que \\(j=1,...,p\\) e \\(p\\) é o número de parâmetros do modelo.\n\n\\(Y\\) é um vetor \\(n\\times 1\\) correspondente a variável resposta do estudo;\n\\(\\beta_0\\) e \\(\\boldsymbol{\\beta}\\) correspondem aos parâmetros do modelo, e \\(\\boldsymbol{\\beta}\\) é um vetor \\(p\\times 1\\);\n\\(\\boldsymbol{X}\\) é a matriz de planejamento \\(n\\times p\\) correspondente às variáveis independentes do modelo;\n\\(\\boldsymbol{\\varepsilon}_i\\) corresponde ao erro experimental, do qual não podemos controlar. Também é conhecido como resíduo.\n\nÉ importante ressaltar que neste relatório iremos expressar qualquer matriz ou vetor por letras em negrito. Além disso, para o uso desses modelos é preciso que algumas suposições sejam aceitas, tais como:\n\nOs erros (ou resíduos) devem seguir uma distribuição Normal e serem independentes;\nOs erros devem possuir médias iguais a zero e serem homocedásticos (variâncias constantes para cada indivíduo)."
  },
  {
    "objectID": "07-multivariada.html#redes-neurais-artificiais",
    "href": "07-multivariada.html#redes-neurais-artificiais",
    "title": "4  Multivariada",
    "section": "4.1 Redes Neurais Artificiais",
    "text": "4.1 Redes Neurais Artificiais\nRedes neurais artificiais é um método baseado na estrutura de funcionamento dos neurônios do cérebro humano. A arquitetura do método é semelhante a todo o processo que ocorre com os neurônios, quanto a forma de aprendizado e repasse de informação entre neurônios através dos dendritos. A estrutura básica de um neurônio biológico é composto por três seções: o corpo da célula, os dendritos e o axônio. A figura 2.1 é uma ilustração da estrutura de um neurônio biológico\n\nA partir de inúmeros estudos na área, um modelo em particular baseado em neurônio biológico foi proposto por Warren S. McCulloch e Walter Pitts no ano de 1943 em um artigo chamado: “A logical calculus of the ideas immanent in nervous activit”, que é uma simplificação do que se sabia até então sobre o neurônio biológico, este modelo foi chamado de MCP.\n\n4.1.1 Modelo MCP\nA representação matemática do modelo MCP contém \\(n\\) terminais \\(x_1, x_2, ..., x_n\\) (representando os dendritos) e um \\(y\\) (axônio) representando o terminal de saída. Para simular o comportamento das sinapses, os terminais de entrada do neurônio tem pesos \\(W_1, W_2, ..., W_n\\) associados cujo os valores podem ser positivos ou negativos.\nNo modelo MCP a ativação de um neurônio é obtida através de uma função de ativação, que ativa ou não a saída, dependendo do valor da soma ponderada das suas entradas (Braga, 2007). O modelo terá a saída ativada quando\n\\[\\begin{eqnarray}\n    \\sum_{i=1}^{n}x_i W_i \\geq \\theta,\n\\end{eqnarray}\\]\nem que \\(n\\) é o número de entradas, \\(W_i\\) é o peso associado a entrada \\(x_i\\), e \\(\\theta\\) (threshold) é o limiar do neurônio. A figura 2.2 ilustra o processo do modelo MCP de um neurônio artificial\n\n\n\n4.1.2 Funções de ativação\nApós McCulloch e Pitts terem proposto um modelo, derivou-se outros modelos que permitem a saída não apenas zero ou um, mas diferentes valores para y. Esse processamento se dá pelo que chamamos função de ativação (Braga, 2007). Será exemplificado três tipos de função de ativação :\n\nFunção Linear, definida como:\n\n\\[\\begin{eqnarray}\n    \\hat{y} = \\alpha x,\n\\end{eqnarray}\\]\nno qual \\(\\hat{y}\\) é a saída do modelo, \\(x\\) os valores de entrada e \\(\\alpha\\) uma constante de linearidade. No qual o máximo que y pode assumir é \\(\\gamma\\) e mínimo -\\(\\gamma\\)\n\nFunção Degrau, definida como\n\n\nFunção Logística, definida como\n\n\\[\\begin{eqnarray}\n        \\hat{y} = \\frac{1}{1 + \\epsilon^{x/T}},\n    \\end{eqnarray}\\]\nonde \\(T\\) determina a suavidade da curva, que será utilizada como função de ligação no modelo proposto.\n\n\n4.1.3 Erro e Atualização dos pesos no MCP\nQuando se estima um parâmetro, é esperado que o mesmo apresente algum desvio em torno do valor real. Com o objetivo de minimizar a diferença entre eles, o algorítimo de aprendizado do perceptron dispõe de regras que permite a adaptação dos seus pesos de forma que a rede execute uma determinada tarefa de classificação.\nO algoritmo consiste em atualizar os pesos de modo que estejam mais próximos da solução desejada que os anteriores. A atualização do peso é dada por $\n\\[\\begin{eqnarray}\n    W(t+1) = W(t) + \\Delta W,\n\\end{eqnarray}\\]\nem que \\(W(t)\\) é o peso no instante \\(t\\) e \\(\\Delta W= \\eta x\\) o incremento associado ao peso, sendo \\(\\eta\\) a taxa de aprendizado.\nVamos denotar \\(x\\) o vetor de entrada, \\(y\\) o vetor da saída desejada, e {x,\\(y\\)} o nodo arbitrário da rede. A atual saída da rede será chamada de \\(\\hat{y}\\), ou seja, uma estimação do valores ideais, mas com um determinado erro \\(\\epsilon\\). Dessa forma podemos denotar o erro como\n\\[\\begin{eqnarray}\n    \\epsilon = y - \\hat{y}.\n\\end{eqnarray}\\]\nPara o caso perceptron, \\(y\\) \\(\\in\\) \\(\\{0,1\\}\\) e \\(\\hat{y}\\) \\(\\in\\) {0,1}. Dessa forma existem quatro possíveis soluções para \\(\\epsilon\\). Se \\(\\epsilon = 0\\) então encontramos valores estimados ideais. Caso contrario \\(\\epsilon\\) pode assumir valores \\(\\{-1,1\\}\\). Se \\(\\epsilon =-1\\) implica que \\(y = 0\\) e $ = 1$, mas se \\(\\epsilon =1\\) então \\(y = 1\\) e \\(\\hat{y} = 0\\). Com o valor de \\(\\epsilon\\) podemos ter uma ideia quanto a direção com que os valores estimados estão distante dos valores ideias (Braga, 2007).\nFeito isso, sabemos que \\(\\Delta W\\)=\\(\\eta x\\) e \\(w(t + 1) = w(t) + \\epsilon \\eta x\\). Quando \\(\\epsilon = 1\\) a equação de atualização dos pesos possui a forma \\(W(t+1)= w(t) + \\eta x\\). Mas para \\(\\epsilon = -1\\) temos a equação \\(W(t+1)= w(t) - \\eta x\\).\n\n\n4.1.4 Multilayer Perceptron (MLP)\nO MLP é uma rede neural semelhante ao perceptron, mas com duas ou mais camadas de neurônios, sendo essas camadas ligadas entre si por sinapses com pesos. O aprendizado deste tipo de rede é feito geralmente pelo algoritmo back-propagation (retro-propagação do erro), porém existem outros algoritmos para serem usados com a mesma finalidade. A figura 2.3 ilustra a estrutura do modelo MLP quanto as entradas (inputs), camadas e a resposta obtida\n\nDe forma simplificada a estrutura matemática do modelo é semelhante a do modelo perceptron sendo apenas adicionadas mais camadas de neurônios. A ativação via função de ativação é geralmente feita com a função sigmoidal comumente chamada de função logística (Braga, 2007).\n\n\n4.1.5 Algoritmo back-propagation\nO algoritmo back-propagation é um algoritmo supervisionado que utiliza pares como entrada e saída desejada para por meio de um mecanismo de correção de erros atualizar os pesos. O treinamento tem duas fases chamadas de forward e backward, sendo que o algoritmo percorre a rede em um sentido para cada fase. A fase farward define a saida de rede para uma dada entrada inserida no modelo e a fase backward utiliza a saida fornecida e a saida desejada para atualizar os pesos de sua conexões visando a diminuição do erro (Haykin, 2007). A figura 2.4 ilustra o processo do algoritmo\n\nO algoritmo back-propagation é baseado na regra delta, sendo chamado também de regra delta generalizada. Os ajustes dos pesos são feitos utilizando-se o método gradiente. A função de custo a ser minimizada é dada pela soma dos erros quadráticos\n\\[\\begin{eqnarray}\n    E = \\frac{1}{2}\\sum_{p}\\sum_{i=1}^{k}(y_{i}^{p}-\\hat{y}_{i}^{p}),\n\\end{eqnarray}\\]\nem que \\(p\\) é o número de padrões, \\(k\\) é o número de unidades de saída, \\(y_{i}\\) é a i-ésima saída desejada e \\(\\hat{y}_{i}\\) é a i-ésima saída da rede."
  },
  {
    "objectID": "07-multivariada.html#análise-de-componentes-principais",
    "href": "07-multivariada.html#análise-de-componentes-principais",
    "title": "4  Multivariada",
    "section": "4.2 Análise de Componentes Principais",
    "text": "4.2 Análise de Componentes Principais\nA análise de componentes principais é uma técnica estatística multivariada que consiste na diminuição da quantidade de variáveis em componentes que a partir delas podemos explicar uma determinada proporção da variabilidade total dos dados utilizando apenas as componentes que são essencialmente em menor número que as variáveis.\nSeja \\(a_{ik}\\) autovetor correspondente a i-ésima componente principal e a uma variável \\(k\\). Logo, a n-ésima componente principal para uma observação da amostra \\(j\\), denominada por \\(c_{n}^{j}\\) definida por: \\[c_{n}^{j}=\\sum_{l=1}^{k}a_{nl}x_{l}^{j},\\] onde, \\(x_{l}^{j}\\) representa o valor da l-ésima variável para uma observação j da amostra.\nPara o estudo em questão, os bancos de dados observados foram os do ano de 2014 e 2006 fornecidos pela cliente. Podemos representar matricialmente cada um dos bancos de dados na seguinte forma:\nonde, \\(n\\) é o número de variáveis associadas ao estudo sendo as colunas do nosso banco de dados, e \\(d\\) é a quantidade de observações em cada variável sendo o número de linhas do banco de dados. Com base na matriz de correlação fornecida podemos obter o vetor de autovalores e seus respectivos autovetores.\nO vetor de autovalores pode ser representado da seguinte forma:\nCada autovalor possui um autovetor que é associado a quantidade de variáveis observadas originalmente (número de colunas). Dessa forma, temos \\(p\\) (quantidade de componentes) autovetores cada um com \\(n\\) (quantidade de variáveis) observações, ou seja, \\(n\\) linhas. Os autovetores podem ser representados matricialmente da seguinte forma:\nConforme definido anteriormente, o cálculo da n-ésima componente principal para uma observação da amostra j, denominada por \\(c_{n}^{j}\\) é definida por:\n\\[c_{n}^{j}=\\sum_{l=1}^{17}a_{nl}x_{l}^{j}.\\]\nPara facilitar o entendimento, a matriz com todas as componentes principais pode ser representada da seguinte forma:\nO índice de capital social para cada observação \\(j\\), denominado por \\(ICS_j\\), é dado por:\n\\[ICS_j=\\frac{1}{\\sum_{k=1}^{p}\\lambda_k}\\sum_{k=1}^{p}\\lambda_k c_{k}^{j},\\] em que \\(\\lambda_k\\) representa o autovalor associado à k-ésima componente principal, sendo \\(p\\) o número de componentes principais utilizadas na construção do índice (quantidade definida a partir da variabilidade miníma explicada aceitável).\nO vetor com todos os índices são dados na forma:\nsendo \\(d\\) o número de observações."
  },
  {
    "objectID": "08-amostragem.html#amostragem-por-conglomerado---ac",
    "href": "08-amostragem.html#amostragem-por-conglomerado---ac",
    "title": "5  Amostragem",
    "section": "5.1 Amostragem por conglomerado - AC",
    "text": "5.1 Amostragem por conglomerado - AC"
  },
  {
    "objectID": "08-amostragem.html#amostragem-estratificada---ae",
    "href": "08-amostragem.html#amostragem-estratificada---ae",
    "title": "5  Amostragem",
    "section": "5.2 Amostragem Estratificada - AE",
    "text": "5.2 Amostragem Estratificada - AE"
  },
  {
    "objectID": "08-amostragem.html#amostragem-poisson---ap",
    "href": "08-amostragem.html#amostragem-poisson---ap",
    "title": "5  Amostragem",
    "section": "5.3 Amostragem Poisson - AP",
    "text": "5.3 Amostragem Poisson - AP"
  },
  {
    "objectID": "08-amostragem.html#amostragem-binomial---ab",
    "href": "08-amostragem.html#amostragem-binomial---ab",
    "title": "5  Amostragem",
    "section": "5.4 Amostragem Binomial - AB",
    "text": "5.4 Amostragem Binomial - AB"
  },
  {
    "objectID": "08-amostragem.html#amostragem-aleatória-sistemática---as",
    "href": "08-amostragem.html#amostragem-aleatória-sistemática---as",
    "title": "5  Amostragem",
    "section": "5.5 Amostragem Aleatória Sistemática - AS",
    "text": "5.5 Amostragem Aleatória Sistemática - AS"
  },
  {
    "objectID": "08-amostragem.html#amostragem-aleatória-simples-com-reposição---aasc",
    "href": "08-amostragem.html#amostragem-aleatória-simples-com-reposição---aasc",
    "title": "5  Amostragem",
    "section": "5.6 Amostragem Aleatória Simples com reposição - AASc",
    "text": "5.6 Amostragem Aleatória Simples com reposição - AASc"
  },
  {
    "objectID": "06-regressao.html#modelos-lineares-generalizados",
    "href": "06-regressao.html#modelos-lineares-generalizados",
    "title": "3  Regressão",
    "section": "3.7 Modelos Lineares Generalizados",
    "text": "3.7 Modelos Lineares Generalizados"
  },
  {
    "objectID": "06-regressao.html#análise-de-resíduos",
    "href": "06-regressao.html#análise-de-resíduos",
    "title": "3  Regressão",
    "section": "3.8 Análise de Resíduos",
    "text": "3.8 Análise de Resíduos\n\n3.8.1 Distância de Cook\n\n\n3.8.2 Grafíco Envolope e Normalidade dos Resíduos\n\n\n3.8.3 Outras diagnósticos dos Resíduos"
  },
  {
    "objectID": "07-multivariada.html#análise-de-componetes-principaispca",
    "href": "07-multivariada.html#análise-de-componetes-principaispca",
    "title": "4  Multivariada",
    "section": "4.3 Análise de componetes principais(PCA)",
    "text": "4.3 Análise de componetes principais(PCA)"
  },
  {
    "objectID": "07-multivariada.html#análise-de-cluster",
    "href": "07-multivariada.html#análise-de-cluster",
    "title": "4  Multivariada",
    "section": "4.4 Análise de Cluster",
    "text": "4.4 Análise de Cluster"
  }
]